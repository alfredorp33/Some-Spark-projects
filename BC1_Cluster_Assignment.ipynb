{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 1000)\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.clustering import KMeans, KMeansModel, BisectingKMeans, BisectingKMeansModel\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, PCA, PCAModel, ElementwiseProduct\n",
    "from pyspark.sql.functions import current_date, broadcast\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standarization and Model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkFeaturePipelineModel=PipelineModel.load(\"/analytics/bc1_clustering/models/pipeline12DicGrp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformer=ElementwiseProduct.load(\"/analytics/bc1_clustering/models/scaleFinancial12DicGrp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=BisectingKMeansModel.load(\"/analytics/bc1_clustering/models/model2DicGrp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfOrden=spark.read.parquet('/analytics/bc1_clustering/tables/dfOrden12DicGrp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User - Product dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HERE WE'D PROCESS THE DATA JUST AS IN THE DATA WRANGLING TO GET BUFFER TICKET USER-PRODUCT \n",
    "# AS IT IS SAVED, I'LL JUST LOAD IT FOR THE DEVELOPMENT\n",
    "dfBuffer=spark.read.parquet(\"/analytics/bc1_clustering/tables/dfFinalMatrix11Dic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfBufferFeatureTmp=sparkFeaturePipelineModel.transform(dfBuffer)\n",
    "# dfBufferFeature=sparkFeaturePipelineModel.transform(dfBuffer.withColumnRenamed('','NULO'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfBufferFeature=transformer.transform(dfBufferFeatureTmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfSegmentation=model.transform(dfBufferFeature).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinalSegmentation=dfSegmentation.join(broadcast(dfOrden),dfSegmentation.prediction==dfOrden.prediction) \\\n",
    "    .orderBy('orden').select(\"ACCOUNTPK\",dfSegmentation.prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|ACCOUNTPK|prediction|\n",
      "+---------+----------+\n",
      "|   380612|        12|\n",
      "|   530868|        12|\n",
      "|   564430|        12|\n",
      "|   632370|        12|\n",
      "|   833333|        12|\n",
      "+---------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfFinalSegmentation.persist().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4166747"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFinalSegmentation.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinalSegmentation.coalesce(1) \\\n",
    "    .write.csv('/analytics/bc1_clustering/outputs/output12DicGrpx4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time.strftime('%Y%m%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
